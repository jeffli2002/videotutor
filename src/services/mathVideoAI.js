export class MathVideoAIService {
  constructor() {
    this.config = {
      // ä¸»è¦AIæœåŠ¡é…ç½®
      openai: {
        apiKey: import.meta.env.VITE_OPENAI_API_KEY,
        baseUrl: 'https://api.openai.com/v1'
      },
      // é˜¿é‡Œäº‘é€šä¹‰åƒé—® - æ€§ä»·æ¯”é«˜çš„ä¸­æ–‡æ•°å­¦ç†è§£
      qwen: {
        apiKey: import.meta.env.VITE_QWEN_API_KEY,
        baseUrl: 'https://dashscope.aliyuncs.com/api/v1'
      },
      // D-IDæˆ–HeyGenç”¨äºè™šæ‹Ÿè®²å¸ˆè§†é¢‘ç”Ÿæˆ
      did: {
        apiKey: import.meta.env.VITE_DID_API_KEY,
        baseUrl: 'https://api.d-id.com'
      },
      // Azure Speech Servicesç”¨äºå¤šè¯­è¨€TTS
      azure: {
        apiKey: import.meta.env.VITE_AZURE_SPEECH_KEY,
        region: import.meta.env.VITE_AZURE_REGION
      },
      // Manim Communityç”¨äºæ•°å­¦åŠ¨ç”»æ¸²æŸ“
      manim: {
        endpoint: import.meta.env.VITE_MANIM_API_ENDPOINT || 'http://localhost:5001'
      }
    }
    
    this.supportedLanguages = {
      'en': { name: 'English', voice: 'en-US-AriaNeural', mathTerms: 'english' },
      'zh': { name: 'ä¸­æ–‡', voice: 'zh-CN-XiaoxiaoNeural', mathTerms: 'chinese' },
      'es': { name: 'EspaÃ±ol', voice: 'es-ES-ElviraNeural', mathTerms: 'spanish' },
      'fr': { name: 'FranÃ§ais', voice: 'fr-FR-DeniseNeural', mathTerms: 'french' },
      'ja': { name: 'æ—¥æœ¬èª', voice: 'ja-JP-NanamiNeural', mathTerms: 'japanese' }
    }
  }

  async generateMathVideo(question, options = {}) {
    const {
      language = 'en',
      difficulty = 'intermediate',
      style = 'step-by-step',
      includeAnimation = true,
      voiceGender = 'female'
    } = options

    try {
      // æ­¥éª¤1: æ•°å­¦é—®é¢˜ç†è§£å’Œæ±‚è§£
      const mathSolution = await this.solveMathProblem(question, language, difficulty)
      
      // æ­¥éª¤2: ç”Ÿæˆæ•™å­¦è„šæœ¬
      const teachingScript = await this.generateTeachingScript(mathSolution, language, style)
      
      // æ­¥éª¤3: åˆ›å»ºæ•°å­¦åŠ¨ç”»
      const animations = includeAnimation ? 
        await this.generateMathAnimations(mathSolution, teachingScript) : null
      
      // æ­¥éª¤4: ç”Ÿæˆå¤šè¯­è¨€è¯­éŸ³
      const audioTrack = await this.generateVoiceover(teachingScript, language, voiceGender)
      
      // æ­¥éª¤5: åˆæˆæœ€ç»ˆè§†é¢‘
      const finalVideo = await this.combineVideoElements(
        teachingScript, 
        animations, 
        audioTrack, 
        language
      )
      
      return {
        success: true,
        video: finalVideo,
        metadata: {
          duration: finalVideo.duration,
          language,
          difficulty,
          mathTopics: mathSolution.topics,
          processingTime: finalVideo.processingTime
        }
      }
      
    } catch (error) {
      console.error('Video generation failed:', error)
      return {
        success: false,
        error: error.message,
        fallback: await this.generateFallbackContent(question, language)
      }
    }
  }

  async solveMathProblem(question, language, difficulty) {
    // ä½¿ç”¨é€šä¹‰åƒé—®å¤„ç†ä¸­æ–‡æ•°å­¦é—®é¢˜ï¼ŒOpenAIå¤„ç†è‹±æ–‡
    const useQwen = language === 'zh' || language.startsWith('zh')
    
    const prompt = this.buildMathSolvingPrompt(question, language, difficulty)
    
    try {
      let response
      if (useQwen) {
        response = await this.callQwenAPI(prompt)
      } else {
        response = await this.callOpenAIAPI(prompt)
      }
      
      return {
        originalQuestion: question,
        language,
        solution: response.solution,
        steps: response.steps,
        explanation: response.explanation,
        topics: response.topics,
        difficulty: response.assessedDifficulty,
        alternativeMethods: response.alternatives || []
      }
    } catch (error) {
      throw new Error(`Math solving failed: ${error.message}`)
    }
  }

  buildMathSolvingPrompt(question, language, difficulty) {
    const languageInstructions = {
      'en': 'Solve this math problem step by step in English',
      'zh': 'è¯·ç”¨ä¸­æ–‡é€æ­¥è§£å†³è¿™ä¸ªæ•°å­¦é—®é¢˜',
      'es': 'Resuelve este problema matemÃ¡tico paso a paso en espaÃ±ol',
      'fr': 'RÃ©solvez ce problÃ¨me mathÃ©matique Ã©tape par Ã©tape en franÃ§ais',
      'ja': 'ã“ã®æ•°å­¦å•é¡Œã‚’æ—¥æœ¬èªã§æ®µéšçš„ã«è§£ã„ã¦ãã ã•ã„'
    }
    
    return `
${languageInstructions[language] || languageInstructions['en']}:

Question: ${question}
Difficulty Level: ${difficulty}

Please provide:
1. Complete step-by-step solution
2. Clear explanation for each step
3. Final answer with verification
4. Key mathematical concepts involved
5. Common mistakes to avoid
6. Visual elements that would help understanding

Format your response as JSON with the following structure:
{
  "solution": "final answer",
  "steps": [
    {
      "stepNumber": 1,
      "description": "what we're doing",
      "operation": "mathematical operation",
      "result": "result of this step",
      "explanation": "why we do this",
      "visualHint": "how to show this visually"
    }
  ],
  "explanation": "overall explanation",
  "topics": ["topic1", "topic2"],
  "assessedDifficulty": "actual difficulty level",
  "commonMistakes": ["mistake1", "mistake2"],
  "visualElements": ["element1", "element2"]
}
`
  }

  async callQwenAPI(prompt) {
    const response = await fetch(`${this.config.qwen.baseUrl}/services/aigc/text-generation/generation`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.config.qwen.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'qwen-plus', // æ€§ä»·æ¯”æœ€é«˜çš„æ¨¡å‹
        input: {
          messages: [
            {
              role: 'system',
              content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦è€å¸ˆï¼Œæ“…é•¿ç”¨æ¸…æ™°çš„ä¸­æ–‡è§£é‡Šæ•°å­¦æ¦‚å¿µå’Œè§£é¢˜æ­¥éª¤ã€‚'
            },
            {
              role: 'user',
              content: prompt
            }
          ]
        },
        parameters: {
          temperature: 0.1, // ç¡®ä¿æ•°å­¦ç­”æ¡ˆçš„å‡†ç¡®æ€§
          max_tokens: 2000
        }
      })
    })
    
    const data = await response.json()
    return JSON.parse(data.output.text)
  }

  async callOpenAIAPI(prompt) {
    const response = await fetch(`${this.config.openai.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.config.openai.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo', // æ€§ä»·æ¯”è€ƒè™‘
        messages: [
          {
            role: 'system',
            content: 'You are an expert math teacher who explains concepts clearly and systematically.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.1,
        max_tokens: 2000
      })
    })
    
    const data = await response.json()
    return JSON.parse(data.choices[0].message.content)
  }

  async generateTeachingScript(mathSolution, language, style) {
    const scriptPrompt = this.buildScriptPrompt(mathSolution, language, style)
    
    const useQwen = language === 'zh' || language.startsWith('zh')
    let response
    
    if (useQwen) {
      response = await this.callQwenAPI(scriptPrompt)
    } else {
      response = await this.callOpenAIAPI(scriptPrompt)
    }
    
    return {
      title: response.title,
      introduction: response.introduction,
      scenes: response.scenes,
      conclusion: response.conclusion,
      totalDuration: response.estimatedDuration,
      language
    }
  }

  buildScriptPrompt(mathSolution, language, style) {
    const styleInstructions = {
      'step-by-step': 'Focus on clear, sequential steps with pauses for understanding',
      'conceptual': 'Emphasize the underlying mathematical concepts and intuition',
      'visual': 'Heavy emphasis on visual demonstrations and animations',
      'interactive': 'Include questions and checkpoints for student engagement'
    }
    
    return `
Create a detailed video teaching script in ${language} for this math solution:

Problem: ${mathSolution.originalQuestion}
Solution: ${JSON.stringify(mathSolution, null, 2)}
Style: ${style} - ${styleInstructions[style]}

Create a script with these specifications:
- Total duration: 3-5 minutes
- Clear introduction, main content, and conclusion
- Specific timing for each scene
- Visual cues for animations
- Natural, conversational tone appropriate for students
- Include transition phrases between concepts

Format as JSON:
{
  "title": "lesson title",
  "introduction": {
    "text": "opening script",
    "duration": 30,
    "visuals": ["visual cues"]
  },
  "scenes": [
    {
      "sceneNumber": 1,
      "text": "narration text",
      "duration": 45,
      "visuals": ["what to show on screen"],
      "animations": ["animation descriptions"],
      "emphasis": ["key points to highlight"]
    }
  ],
  "conclusion": {
    "text": "closing script",
    "duration": 30,
    "visuals": ["final visuals"]
  },
  "estimatedDuration": 300
}
`
  }

  async generateMathAnimations(mathSolution, teachingScript) {
    // è°ƒç”¨ManimæœåŠ¡ç”Ÿæˆæ•°å­¦åŠ¨ç”»
    try {
      const animationRequest = {
        scenes: teachingScript.scenes.map(scene => ({
          sceneId: scene.sceneNumber,
          duration: scene.duration,
          mathContent: this.extractMathContent(scene),
          animationType: this.determineAnimationType(scene.animations),
          style: 'educational'
        })),
        resolution: '1920x1080',
        fps: 30,
        backgroundColor: '#ffffff'
      }
      
      const response = await fetch(`${this.config.manim.endpoint}/generate-animation`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(animationRequest)
      })
      
      const result = await response.json()
      return result.animations
      
    } catch (error) {
      console.warn('Animation generation failed, using static visuals:', error)
      return this.generateStaticVisuals(mathSolution, teachingScript)
    }
  }

  async generateVoiceover(teachingScript, language, voiceGender) {
    const voiceConfig = this.supportedLanguages[language]
    if (!voiceConfig) {
      throw new Error(`Unsupported language: ${language}`)
    }
    
    // ç»„åˆæ‰€æœ‰è„šæœ¬æ–‡æœ¬
    const fullScript = [
      teachingScript.introduction.text,
      ...teachingScript.scenes.map(scene => scene.text),
      teachingScript.conclusion.text
    ].join('\n\n')
    
    try {
      // ä½¿ç”¨Azure Speech Servicesç”Ÿæˆé«˜è´¨é‡TTS
      const response = await fetch(
        `https://${this.config.azure.region}.tts.speech.microsoft.com/cognitiveservices/v1`,
        {
          method: 'POST',
          headers: {
            'Ocp-Apim-Subscription-Key': this.config.azure.apiKey,
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': 'riff-24khz-16bit-mono-pcm'
          },
          body: this.buildSSMLScript(fullScript, voiceConfig.voice, language)
        }
      )
      
      const audioBuffer = await response.arrayBuffer()
      return {
        audioData: audioBuffer,
        duration: this.estimateAudioDuration(fullScript, language),
        voice: voiceConfig.voice,
        language
      }
      
    } catch (error) {
      throw new Error(`Voice generation failed: ${error.message}`)
    }
  }

  buildSSMLScript(text, voice, language) {
    // ä¸ºæ•°å­¦æœ¯è¯­æ·»åŠ ç‰¹æ®Šå‘éŸ³æ ‡è®°
    const mathTermsProcessed = this.processMathTerms(text, language)
    
    return `
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="${language}">
  <voice name="${voice}">
    <prosody rate="0.9" pitch="medium">
      ${mathTermsProcessed}
    </prosody>
  </voice>
</speak>`
  }

  processMathTerms(text, language) {
    const mathTerms = {
      'en': {
        'x': '<say-as interpret-as="characters">x</say-as>',
        'Â²': '<say-as interpret-as="characters">squared</say-as>',
        'Â³': '<say-as interpret-as="characters">cubed</say-as>',
        'âˆš': 'square root of',
        'Ï€': 'pi'
      },
      'zh': {
        'x': '<say-as interpret-as="characters">x</say-as>',
        'Â²': 'çš„å¹³æ–¹',
        'Â³': 'çš„ç«‹æ–¹',
        'âˆš': 'æ ¹å·',
        'Ï€': 'åœ†å‘¨ç‡'
      }
    }
    
    const terms = mathTerms[language] || mathTerms['en']
    let processedText = text
    
    Object.entries(terms).forEach(([symbol, pronunciation]) => {
      processedText = processedText.replace(new RegExp(symbol, 'g'), pronunciation)
    })
    
    return processedText
  }

  async combineVideoElements(script, animations, audioTrack, language) {
    // ä½¿ç”¨D-IDæˆ–ç±»ä¼¼æœåŠ¡åˆ›å»ºè™šæ‹Ÿè®²å¸ˆè§†é¢‘
    try {
      const videoRequest = {
        script: {
          type: 'text',
          input: script.scenes.map(scene => scene.text).join(' '),
          language: language
        },
        config: {
          fluent: true,
          pad_audio: 0.0
        },
        source_url: this.getAvatarForLanguage(language) // é€‰æ‹©åˆé€‚çš„è™šæ‹Ÿè®²å¸ˆ
      }
      
      const response = await fetch(`${this.config.did.baseUrl}/talks`, {
        method: 'POST',
        headers: {
          'Authorization': `Basic ${this.config.did.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(videoRequest)
      })
      
      const result = await response.json()
      
      // ç­‰å¾…è§†é¢‘ç”Ÿæˆå®Œæˆ
      const finalVideo = await this.pollVideoStatus(result.id)
      
      return {
        videoUrl: finalVideo.result_url,
        thumbnailUrl: finalVideo.thumbnail_url,
        duration: finalVideo.duration,
        processingTime: finalVideo.processing_time,
        quality: '1920x1080',
        format: 'mp4'
      }
      
    } catch (error) {
      throw new Error(`Video combination failed: ${error.message}`)
    }
  }

  getAvatarForLanguage(language) {
    const avatars = {
      'en': 'https://d-id-public-bucket.s3.amazonaws.com/alice.jpg',
      'zh': 'https://d-id-public-bucket.s3.amazonaws.com/chinese-teacher.jpg',
      'es': 'https://d-id-public-bucket.s3.amazonaws.com/maria.jpg',
      'fr': 'https://d-id-public-bucket.s3.amazonaws.com/sophie.jpg',
      'ja': 'https://d-id-public-bucket.s3.amazonaws.com/yuki.jpg'
    }
    
    return avatars[language] || avatars['en']
  }

  async pollVideoStatus(videoId, maxAttempts = 30) {
    for (let i = 0; i < maxAttempts; i++) {
      await new Promise(resolve => setTimeout(resolve, 10000)) // ç­‰å¾…10ç§’
      
      const response = await fetch(`${this.config.did.baseUrl}/talks/${videoId}`, {
        headers: {
          'Authorization': `Basic ${this.config.did.apiKey}`
        }
      })
      
      const status = await response.json()
      
      if (status.status === 'done') {
        return status
      } else if (status.status === 'error') {
        throw new Error(`Video generation failed: ${status.error}`)
      }
      
      // çŠ¶æ€ä»åœ¨å¤„ç†ä¸­ï¼Œç»§ç»­ç­‰å¾…
    }
    
    throw new Error('Video generation timeout')
  }

  // æˆæœ¬ä¼°ç®—æ–¹æ³•
  estimateCost(duration, language, includeAnimation = true) {
    const costs = {
      // OpenAI API costs (per 1K tokens)
      openai: 0.002,
      // é€šä¹‰åƒé—® costs (per 1K tokens) - æ›´ä¾¿å®œ
      qwen: 0.0008,
      // Azure Speech costs (per character)
      azureTTS: 0.000004,
      // D-ID costs (per minute)
      didVideo: 0.3,
      // Manim animation (per scene)
      animation: 0.1
    }
    
    const useQwen = language === 'zh'
    const llmCost = useQwen ? costs.qwen : costs.openai
    
    return {
      llm: llmCost * 2, // ä¼°ç®—2K tokens
      tts: costs.azureTTS * duration * 200, // ä¼°ç®—æ¯åˆ†é’Ÿ200å­—ç¬¦
      video: costs.didVideo * (duration / 60),
      animation: includeAnimation ? costs.animation * 5 : 0, // ä¼°ç®—5ä¸ªåœºæ™¯
      total: function() {
        return this.llm + this.tts + this.video + this.animation
      }
    }
  }

  // è¾…åŠ©æ–¹æ³•
  extractMathContent(scene) {
    const mathPatterns = [
      /\d+[xy]\s*[+\-*/]\s*\d+/g, // åŸºæœ¬ä»£æ•°è¡¨è¾¾å¼
      /[xy]\s*=\s*\d+/g, // ç­‰å¼
      /\d+\/\d+/g, // åˆ†æ•°
      /âˆš\d+/g, // æ ¹å·
      /\d+Â²/g, // å¹³æ–¹
    ]
    
    const mathContent = []
    mathPatterns.forEach(pattern => {
      const matches = scene.text.match(pattern)
      if (matches) {
        mathContent.push(...matches)
      }
    })
    
    return mathContent
  }

  determineAnimationType(animations) {
    if (!animations || animations.length === 0) return 'static'
    
    const animationKeywords = {
      'equation': ['solve', 'step', 'substitute'],
      'graph': ['plot', 'line', 'curve'],
      'geometry': ['triangle', 'circle', 'angle'],
      'algebra': ['variable', 'expression', 'simplify']
    }
    
    for (const [type, keywords] of Object.entries(animationKeywords)) {
      if (keywords.some(keyword => 
        animations.some(anim => anim.toLowerCase().includes(keyword))
      )) {
        return type
      }
    }
    
    return 'general'
  }

  estimateAudioDuration(text, language) {
    // ä¸åŒè¯­è¨€çš„è¯­é€Ÿä¼°ç®— (å­—ç¬¦/ç§’)
    const speechRates = {
      'en': 14, // è‹±è¯­çº¦14å­—ç¬¦/ç§’
      'zh': 4,  // ä¸­æ–‡çº¦4å­—ç¬¦/ç§’
      'es': 12, // è¥¿ç­ç‰™è¯­çº¦12å­—ç¬¦/ç§’
      'fr': 13, // æ³•è¯­çº¦13å­—ç¬¦/ç§’
      'ja': 6   // æ—¥è¯­çº¦6å­—ç¬¦/ç§’
    }
    
    const rate = speechRates[language] || speechRates['en']
    return Math.ceil(text.length / rate)
  }

  async generateFallbackContent(question, language) {
    // å¦‚æœä¸»è¦è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œæä¾›æ–‡æœ¬è§£ç­”ä½œä¸ºå¤‡é€‰
    return {
      type: 'text',
      content: `We apologize, but video generation is temporarily unavailable. Here's a text solution for: ${question}`,
      language,
      suggestedAction: 'Try again later or contact support'
    }
  }
}

/**
 * å°†Qwenåˆ†æ­¥è®²è§£è„šæœ¬è½¬ä¸ºä¼˜åŒ–çš„Manim Pythonä»£ç ï¼ˆé¿å…è¶…æ—¶ï¼‰
 * @param {string[]} qwenSteps - Qwen APIè¿”å›çš„åˆ†æ­¥è®²è§£æ•°ç»„
 * @param {string} sceneName - Manimåœºæ™¯å
 * @returns {string} - ä¼˜åŒ–çš„Manim Pythonä»£ç 
 */
export function buildManimScriptFromQwen(qwenSteps, sceneName = "MathSolutionScene") {
  console.log('ğŸ¬ å¼€å§‹æ„å»ºManimè„šæœ¬ï¼ŒåŸå§‹æ­¥éª¤:', qwenSteps)
  
  // æ¸…ç†å’Œé™åˆ¶æ­¥éª¤ï¼Œä¸¥æ ¼ä¿æŒåŸå§‹é¡ºåº
  const maxSteps = 8; // é™åˆ¶æœ€å¤§æ­¥éª¤æ•°ï¼Œé¿å…é‡å¤
  let cleanedSteps = qwenSteps
    .filter(step => step && step.trim())
    .map((step, index) => ({
      content: step.trim(), // å…ˆä¿ç•™åŸå§‹å†…å®¹
      originalIndex: index
    }))
    .filter(step => step.content.length > 0) // åªè¿‡æ»¤ç©ºå†…å®¹
    .slice(0, maxSteps); // é™åˆ¶æ­¥éª¤æ•°é‡

  // æ­¥éª¤å»é‡ï¼Œä¿æŒé¡ºåºï¼Œä½¿ç”¨æ›´æ™ºèƒ½çš„å»é‡é€»è¾‘
  const uniqueSteps = [];
  const seen = new Set();
  for (const step of cleanedSteps) {
    // æå–æ­¥éª¤çš„å…³é”®å†…å®¹ï¼ˆå‰50ä¸ªå­—ç¬¦ï¼‰ç”¨äºå»é‡åˆ¤æ–­
    const keyContent = step.content.substring(0, 50).trim();
    if (!seen.has(keyContent)) {
      uniqueSteps.push(step);
      seen.add(keyContent);
    }
  }
  
  // ç°åœ¨å¯¹å»é‡åçš„æ­¥éª¤è¿›è¡Œæ¸…ç†
  cleanedSteps = uniqueSteps.map(step => cleanTextForManim(step.content));

  console.log('ğŸ§¹ æ¸…ç†åçš„æ­¥éª¤ï¼ˆå»é‡åé¡ºåºï¼‰:', cleanedSteps)
  console.log('ğŸ“Š æ­¥éª¤æ•°é‡:', cleanedSteps.length)
  
  // éªŒè¯æ­¥éª¤é¡ºåºå’Œå†…å®¹
  for (let i = 0; i < cleanedSteps.length; i++) {
    console.log(`Manimæ­¥éª¤ ${i + 1}: ${cleanedSteps[i].substring(0, 100)}${cleanedSteps[i].length > 100 ? '...' : ''}`)
    console.log(`æ­¥éª¤ ${i + 1} å®Œæ•´å†…å®¹é•¿åº¦: ${cleanedSteps[i].length} å­—ç¬¦`)
  }

  // å¦‚æœæ­¥éª¤å¤ªå°‘ï¼Œè‡ªåŠ¨è¡¥å……åŸºç¡€æ­¥éª¤
  if (cleanedSteps.length < 2) {
    cleanedSteps = [
      "åˆ†æé¢˜ç›®æ¡ä»¶", 
      "åˆ—å‡ºæ–¹ç¨‹",
      "ç§»é¡¹æ±‚è§£",
      "è®¡ç®—å¾—å‡ºç»“æœ",
      "éªŒè¯ç­”æ¡ˆ"
    ].slice(0, maxSteps)
    console.log('ğŸ”„ ä½¿ç”¨é»˜è®¤æ­¥éª¤:', cleanedSteps)
  }
  // è½¬æ¢æ­¥éª¤ä¸ºPythonåˆ—è¡¨æ ¼å¼
  const stepsStr = JSON.stringify(cleanedSteps);
  // ç”Ÿæˆä¼˜åŒ–çš„Manimä»£ç 
  const script = `from manim import *
import warnings
warnings.filterwarnings("ignore")

class ${sceneName}(Scene):
    def construct(self):
        self.camera.background_color = WHITE
        
        # æ ‡é¢˜
        title = Text("AIæ•°å­¦è§£ç­”", font_size=36, color=BLUE).to_edge(UP)
        self.play(Write(title), run_time=1)
        self.wait(0.5)
        
        # æ˜¾ç¤ºæ­¥éª¤
        steps = ${stepsStr}
        print(f"Manimæ¸²æŸ“æ­¥éª¤æ•°é‡: {len(steps)}")
        
        previous_text = None
        for i, step_text in enumerate(steps):
            try:
                print(f"æ¸²æŸ“æ­¥éª¤ {i+1}: {step_text[:50]}...")
                
                # æ­¥éª¤ç¼–å·
                step_num = Text(f"æ­¥éª¤ {i+1}", font_size=24, color=RED)
                step_num.next_to(title, DOWN, buff=1)
                
                # æ­¥éª¤å†…å®¹ - æ™ºèƒ½å¤„ç†é•¿æ–‡æœ¬
                if len(step_text) > 80:
                    # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å¥
                    import re
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼›;.!?]', step_text)
                    sentences = [s.strip() for s in sentences if s.strip()]
                    
                    # åˆ›å»ºå¤šè¡Œæ–‡æœ¬ç»„
                    step_content = VGroup()
                    current_y = 0
                    
                    for j, sentence in enumerate(sentences):
                        if len(sentence) > 40:
                            # é•¿å¥å­æŒ‰å­—æ•°åˆ†è¡Œ
                            words = []
                            while len(sentence) > 40:
                                words.append(sentence[:40])
                                sentence = sentence[40:]
                            if sentence:
                                words.append(sentence)
                        else:
                            words = [sentence]
                        
                        for k, word in enumerate(words):
                            line_text = Text(word, font_size=14, color=BLACK)
                            line_text.next_to(step_num, DOWN, buff=0.5 + current_y * 0.35)
                            step_content.add(line_text)
                            current_y += 1
                else:
                    # çŸ­æ–‡æœ¬æ­£å¸¸æ˜¾ç¤º
                    step_content = Text(step_text, font_size=16, color=BLACK, line_spacing=1.2)
                    step_content.next_to(step_num, DOWN, buff=0.5)
                
                # æ·¡å‡ºå‰ä¸€ä¸ªæ­¥éª¤
                if previous_text:
                    self.play(FadeOut(previous_text), run_time=0.8)
                
                # æ˜¾ç¤ºæ–°æ­¥éª¤
                self.play(Write(step_num), run_time=1.2)
                self.play(Write(step_content), run_time=1.5)
                
                # æ ¹æ®å†…å®¹é•¿åº¦è°ƒæ•´ç­‰å¾…æ—¶é—´
                wait_time = max(6.0, len(step_text) * 0.08)  # è‡³å°‘6ç§’ï¼Œæ¯å­—ç¬¦0.08ç§’
                self.wait(wait_time)  # åŠ¨æ€ç­‰å¾…æ—¶é—´ï¼Œè®©ç”¨æˆ·çœ‹æ¸…å®Œæ•´æ­¥éª¤
                
                previous_text = VGroup(step_num, step_content)
                
            except Exception as e:
                print(f"è·³è¿‡æ­¥éª¤ {i+1}: {e}")
                continue
        
        # ç»“æŸæ–‡æœ¬
        end_text = Text("è§£ç­”å®Œæˆ!", font_size=32, color=GREEN)
        if previous_text:
            self.play(FadeOut(previous_text), run_time=0.5)
        self.play(Write(end_text), run_time=1)
        self.wait(2)
`
  return script;
}

/**
 * æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´Manimæ¸²æŸ“é—®é¢˜çš„å­—ç¬¦
 * @param {string} text - åŸå§‹æ–‡æœ¬
 * @returns {string} - æ¸…ç†åçš„æ–‡æœ¬
 */
function cleanTextForManim(text) {
  // ç§»é™¤markdownæ ‡è®°
  text = text.replace(/[#*`]/g, '');
  // ç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€åŸºæœ¬ç¬¦å·å’Œæ•°å­¦ç¬¦å·
  text = text.replace(/[^ - - - \w\s\u4e00-\u9fff,.ï¼Œã€‚ï¼ï¼Ÿ()ï¼ˆï¼‰=+\-*/Ã·Ã—Â²Â³âˆšÏ€âˆâ‰¤â‰¥â‰ â‰ˆÂ±âˆ‘âˆâˆ«âˆ‚âˆ‡âˆ†âˆˆâˆ‰âŠ‚âŠƒâˆªâˆ©âˆ…âˆ€âˆƒ]/g, '');
  // ç§»é™¤å¤šä½™ç©ºæ ¼
  text = text.replace(/\s+/g, ' ').trim();
  
  // ä¿ç•™å®Œæ•´å†…å®¹ï¼Œä¸å¼ºåˆ¶æˆªæ–­
  // åªåœ¨å¿…è¦æ—¶é™åˆ¶é•¿åº¦ï¼ˆè¶…è¿‡500å­—ç¬¦æ‰æˆªæ–­ï¼‰
  if (text.length > 500) {
    text = text.substring(0, 497) + "...";
  }
  
  return text;
}

/**
 * è‡ªåŠ¨è°ƒç”¨Manimæ¸²æŸ“APIç”Ÿæˆè§†é¢‘
 * @param {string[]} qwenSteps - Qwen APIè¿”å›çš„åˆ†æ­¥è®²è§£æ•°ç»„
 * @param {string} outputName - è¾“å‡ºè§†é¢‘æ–‡ä»¶å
 * @returns {Promise<string>} - è¿”å›mp4è§†é¢‘URL
 */
export async function generateManimVideoFromQwen(qwenSteps, outputName = "qwen_video1") {
  const manimScript = buildManimScriptFromQwen(qwenSteps)
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 300000); // 5åˆ†é’Ÿ

  try {
    console.log(`ğŸ¬ å¼€å§‹ç”ŸæˆManimè§†é¢‘: ${outputName}`)
    
    const resp = await fetch("http://127.0.0.1:5001/api/manim_render", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        script: manimScript,
        output_name: outputName,
        scene_name: "MathSolutionScene"
      }),
      signal: controller.signal
    })
    
    clearTimeout(timeoutId);
    
    if (!resp.ok) {
      throw new Error(`HTTPé”™è¯¯: ${resp.status} ${resp.statusText}`)
    }
    
    const data = await resp.json()
    console.log(`ğŸ“„ Manim APIå“åº”:`, data)
    
    if (data.success) {
      console.log(`âœ… Manimè§†é¢‘ç”ŸæˆæˆåŠŸ: ${data.video_url}`)
      return data.video_url
    } else {
      throw new Error(data.error || "Manimæ¸²æŸ“å¤±è´¥")
    }
  } catch (e) {
    clearTimeout(timeoutId);
    console.error(`âŒ Manimæ¸²æŸ“å¤±è´¥:`, e)
    
    if (e.name === 'AbortError') {
      throw new Error("Manimæ¸²æŸ“è¶…æ—¶ï¼Œè¯·ç®€åŒ–é—®é¢˜æˆ–ç¨åé‡è¯•")
    } else if (e.message.includes('fetch') || e.message.includes('Connection refused')) {
      // æœåŠ¡å™¨è¿æ¥å¤±è´¥ï¼Œè¿”å›å›ºå®šçš„æ¨¡æ‹Ÿè§†é¢‘URL
      console.log("ğŸ”„ ManimæœåŠ¡å™¨ä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ‹Ÿè§†é¢‘")
      return `/rendered_videos/fallback_video.mp4`
    } else {
      throw new Error(e.message);
    }
  }
}

export default new MathVideoAIService()